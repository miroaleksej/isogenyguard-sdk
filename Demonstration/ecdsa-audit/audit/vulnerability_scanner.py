"""
Module for scanning ECDSA implementations for specific vulnerabilities.
Focuses on detecting known vulnerability patterns through topological analysis.
"""

from typing import Dict, List, Tuple
import numpy as np
from core.topology_analyzer import TopologyAnalyzer
from core.anomaly_detector import AnomalyDetector

class VulnerabilityScanner:
    def __init__(self):
        self.topology_analyzer = TopologyAnalyzer()
        self.anomaly_detector = AnomalyDetector()
    
    def scan_for_reused_k(self, region: List[List[int]]) -> Dict[str, float]:
        """
        Scans for reused k vulnerability pattern.
        
        Args:
            region: Rₓ table subregion
            
        Returns:
            Detection metrics for reused k vulnerability
        """
        # Reused k creates linear patterns in the table
        # We look for unusually high correlation along specific directions
        
        # Check correlation along potential k-reuse directions
        direction_scores = []
        
        # Test different slopes (d values)
        for slope in range(1, 10):
            correlation = 0
            count = 0
            
            # Check correlation along lines with given slope
            for offset in range(-len(region[0]), len(region)):
                values = []
                for i in range(max(0, offset), min(len(region), offset + len(region[0]))):
                    j = i - offset
                    if 0 <= j < len(region[0]):
                        values.append(region[i][j])
                
                if len(values) > 2:
                    # Calculate autocorrelation
                    values_array = np.array(values)
                    mean_val = np.mean(values_array)
                    variance = np.var(values_array)
                    
                    if variance > 0:
                        acf = np.correlate(values_array - mean_val, values_array - mean_val, mode='full')
                        acf = acf[len(acf)//2:] / variance / len(values_array)
                        correlation += acf[1]  # First lag correlation
                        count += 1
            
            if count > 0:
                avg_correlation = correlation / count
                direction_scores.append((slope, avg_correlation))
        
        # Find direction with highest correlation
        best_direction = max(direction_scores, key=lambda x: x[1])
        
        # Calculate F1-score for vulnerability detection
        # Based on Table 3 in the reference material
        f1_score = min(1.0, best_direction[1] * 2.0)
        
        return {
            "direction": best_direction[0],
            "correlation": best_direction[1],
            "f1_score": f1_score,
            "is_vulnerable": f1_score > 0.85
        }
    
    def scan_for_weak_drbg(self, regions: List[List[List[int]]]) -> Dict[str, float]:
        """
        Scans for weak DRBG (Deterministic Random Bit Generator) patterns.
        
        Args:
            regions: list of Rₓ table subregions
            
        Returns:
            Detection metrics for weak DRBG vulnerability
        """
        # Weak DRBG creates patterns in the table that affect damping coefficient
        gamma_values = [self.topology_analyzer.analyze_spiral_waves(region) for region in regions]
        avg_gamma = np.mean(gamma_values)
        
        # Calculate entropy of gamma distribution
        gamma_entropy = self._calculate_entropy(gamma_values)
        
        # Weak DRBG typically shows low gamma and low entropy
        vulnerability_score = 1.0 - min(1.0, avg_gamma / self.anomaly_detector.gamma_threshold) * gamma_entropy
        
        return {
            "average_gamma": avg_gamma,
            "gamma_entropy": gamma_entropy,
            "vulnerability_score": vulnerability_score,
            "is_vulnerable": vulnerability_score > 0.7
        }
    
    def scan_for_special_point_anomalies(self, region: List[List[int]], u_r: int) -> Dict[str, float]:
        """
        Scans for anomalies around special points.
        
        Args:
            region: Rₓ table subregion
            u_r: specific row to check
            
        Returns:
            Detection metrics for special point anomalies
        """
        # Check symmetry around potential special points
        symmetry_scores = []
        for center in range(len(region[0])):
            # Check symmetry around this point
            symmetry = self.topology_analyzer.check_symmetry([region[u_r]], center)
            symmetry_scores.append((center, symmetry))
        
        # Find point with highest symmetry (should be the special point)
        best_symmetry = max(symmetry_scores, key=lambda x: x[1])
        
        # In secure implementation, symmetry should be high at special point
        # and decrease as we move away
        vulnerability_score = 1.0 - best_symmetry[1]
        
        return {
            "special_point": best_symmetry[0],
            "symmetry_score": best_symmetry[1],
            "vulnerability_score": vulnerability_score,
            "is_vulnerable": vulnerability_score > 0.3
        }
    
    def comprehensive_vulnerability_scan(self, regions: List[List[List[int]]], u_r: int = None) -> Dict:
        """
        Performs comprehensive vulnerability scan across multiple dimensions.
        
        Args:
            regions: list of Rₓ table subregions
            u_r: specific row to check for special point anomalies
            
        Returns:
            Comprehensive vulnerability assessment
        """
        # Run all vulnerability scans
        reused_k_results = [self.scan_for_reused_k(region) for region in regions]
        weak_drbg_result = self.scan_for_weak_drbg(regions)
        
        # For special point analysis, use the first region if u_r is provided
        special_point_result = None
        if u_r is not None and regions:
            special_point_result = self.scan_for_special_point_anomalies(regions[0], u_r)
        
        # Aggregate results
        avg_reused_k_f1 = np.mean([r["f1_score"] for r in reused_k_results])
        reused_k_vulnerable = avg_reused_k_f1 > 0.85
        
        # Calculate overall vulnerability score
        vulnerability_score = (
            0.5 * (1.0 - avg_reused_k_f1) +
            0.3 * weak_drbg_result["vulnerability_score"] +
            (0.2 * special_point_result["vulnerability_score"] if special_point_result else 0)
        )
        
        return {
            "reused_k_analysis": {
                "average_f1_score": avg_reused_k_f1,
                "is_vulnerable": reused_k_vulnerable,
                "per_region": reused_k_results
            },
            "weak_drbg_analysis": weak_drbg_result,
            "special_point_analysis": special_point_result,
            "overall_vulnerability_score": vulnerability_score,
            "critical_vulnerabilities": {
                "reused_k": reused_k_vulnerable,
                "weak_drbg": weak_drbg_result["is_vulnerable"],
                "special_point_anomalies": special_point_result["is_vulnerable"] if special_point_result else False
            },
            "recommendations": self.generate_recommendations(
                reused_k_vulnerable,
                weak_drbg_result["is_vulnerable"],
                special_point_result["is_vulnerable"] if special_point_result else False
            )
        }
    
    def _calculate_entropy(self, values: List[float]) -> float:
        """Calculates entropy of a distribution"""
        # Simple entropy calculation for normalized values
        values = np.array(values)
        values = values / np.sum(values)  # Normalize
        entropy = -np.sum(values * np.log2(values + 1e-10))
        return entropy / np.log2(len(values) + 1)  # Normalize to 0-1 range
    
    def generate_recommendations(self, 
                               reused_k: bool, 
                               weak_drbg: bool, 
                               special_point_anomalies: bool) -> List[str]:
        """
        Generates vulnerability-specific recommendations.
        
        Args:
            reused_k: whether reused k vulnerability was detected
            weak_drbg: whether weak DRBG vulnerability was detected
            special_point_anomalies: whether special point anomalies were detected
            
        Returns:
            List of recommendations
        """
        recommendations = []
        
        if not (reused_k or weak_drbg or special_point_anomalies):
            recommendations.append("No critical vulnerabilities detected in the ECDSA implementation.")
            recommendations.append("The topological analysis shows expected properties for a secure system.")
            return recommendations
        
        if reused_k:
            recommendations.append("CRITICAL: High probability of reused k values detected.")
            recommendations.append("Reused k values can lead to private key recovery through lattice attacks.")
            recommendations.append("Immediate action required: Rotate all affected keys and fix nonce generation process.")
            recommendations.append("Use a cryptographically secure random number generator with proper seeding.")
        
        if weak_drbg:
            recommendations.append("WARNING: Weak random number generation pattern detected.")
            recommendations.append("The damping coefficient analysis suggests potential issues with the DRBG.")
            recommendations.append("Ensure that the random number generator is properly implemented and seeded.")
            recommendations.append("Consider using system-provided CSPRNG (Cryptographically Secure Pseudo-Random Number Generator).")
        
        if special_point_anomalies:
            recommendations.append("WARNING: Anomalies detected around special points in the Rₓ table.")
            recommendations.append("This may indicate implementation issues with the ECDSA signing process.")
            recommendations.append("Verify that all edge cases in the signing algorithm are properly handled.")
        
        return recommendations
